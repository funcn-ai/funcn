---
url: "https://mirascope.com/docs/mirascope/llms-full"
title: "Mirascope - LLMs Text Viewer | Mirascope"
---

# Mirascope - LLMs Text Viewer

Concatenated markdown docs, intended for use by LLMs.

Copy it using the buttons, or navigate to [/docs/mirascope/llms-full.txt](https://mirascope.com/docs/mirascope/llms-full.txt).

## Mirascope

62k tokensCopy

LLM abstractions that aren't obstructions.

### Welcome

1k tokensCopy

Mirascope is a Python library that streamlines working with LLMs

### Quickstart

3k tokensCopy

Get started with Mirascope across various LLM providers

### Learn Mirascope

2k tokensCopy

A comprehensive guide to Mirascope's core components and features. This overview provides a roadmap for learning how to build AI-powered applications with Mirascope.

### Prompts

7k tokensCopy

Master the art of creating effective prompts for LLMs using Mirascope. Learn about message roles, multi-modal inputs, and dynamic prompt configuration.

### Calls

5k tokensCopy

Learn how to make API calls to various LLM providers using Mirascope. This guide covers basic usage, handling responses, and configuring call parameters for different providers.

### Streams

3k tokensCopy

Learn how to process LLM responses in real-time as they are generated using Mirascope's streaming capabilities for more interactive and responsive applications.

### Chaining

3k tokensCopy

Learn how to combine multiple LLM calls in sequence to solve complex tasks through functional chaining, nested chains, conditional execution, and parallel processing.

### Response Models

6k tokensCopy

Learn how to structure and validate LLM outputs using Pydantic models for type safety, automatic validation, and easier data manipulation across different providers.

### JSON Mode

1k tokensCopy

Learn how to request structured JSON outputs from LLMs with Mirascope's JSON Mode for easier parsing, validation, and integration with your applications.

### Output Parsers

2k tokensCopy

Learn how to process and structure raw LLM outputs into usable formats using Mirascope's flexible output parsers for more reliable and application-ready results.

### Tools

14k tokensCopy

Learn how to define, use, and chain together LLM-powered tools in Mirascope to extend model capabilities with external functions, data sources, and system interactions.

### Agents

5k tokensCopy

Learn how to build autonomous and semi-autonomous LLM-powered agents with Mirascope that can use tools, maintain state, and execute multi-step reasoning processes.

### Evals

3k tokensCopy

Learn how to evaluate LLM outputs using multiple approaches including LLM-based evaluators, panels of judges, and hardcoded evaluation criteria.

### Async

2k tokensCopy

Learn how to use asynchronous programming with Mirascope to efficiently handle I/O-bound operations, improve responsiveness, and run multiple LLM calls concurrently.

### Retries

4k tokensCopy

Learn how to implement robust retry mechanisms for LLM API calls using Mirascope and Tenacity to handle rate limits, validation errors, and other failures.

### Local (Open-Source) Models

1k tokensCopy

Learn how to use Mirascope with locally hosted open-source models through Ollama, vLLM, and other APIs with OpenAI compatibility.

[Cross-Product LLM Docs](https://mirascope.com/llms-full)

### Table of Contents

[Cross-Product LLM Docs](https://mirascope.com/llms-full)

### Table of Contents

## Cookie Consent

We use cookies to track usage and improve the site.

RejectAccept