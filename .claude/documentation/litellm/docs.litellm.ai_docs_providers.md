---
url: "https://docs.litellm.ai/docs/providers"
title: "Providers | liteLLM"
---

[Skip to main content](https://docs.litellm.ai/docs/providers#__docusaurus_skipToContent_fallback)

[**🗃️OpenAI** \\
3 items](https://docs.litellm.ai/docs/providers/openai)[**📄️OpenAI (Text Completion)** \\
LiteLLM supports OpenAI text completion models](https://docs.litellm.ai/docs/providers/text_completion_openai)[**📄️OpenAI-Compatible Endpoints** \\
Selecting openai as the provider routes your request to an OpenAI-compatible endpoint using the upstream](https://docs.litellm.ai/docs/providers/openai_compatible)[**🗃️Azure OpenAI** \\
2 items](https://docs.litellm.ai/docs/providers/azure/)[**📄️Azure AI Studio** \\
LiteLLM supports all models on Azure AI Studio](https://docs.litellm.ai/docs/providers/azure_ai)[**📄️AI/ML API** \\
Getting started with the AI/ML API is simple. Follow these steps to set up your integration:](https://docs.litellm.ai/docs/providers/aiml)[**📄️VertexAI \[Anthropic, Gemini, Model Garden\]** \\
Overview](https://docs.litellm.ai/docs/providers/vertex)[**🗃️Google AI Studio** \\
3 items](https://docs.litellm.ai/docs/providers/gemini)[**📄️Anthropic** \\
LiteLLM supports all anthropic models.](https://docs.litellm.ai/docs/providers/anthropic)[**📄️AWS Sagemaker** \\
LiteLLM supports All Sagemaker Huggingface Jumpstart Models](https://docs.litellm.ai/docs/providers/aws_sagemaker)[**🗃️Bedrock** \\
3 items](https://docs.litellm.ai/docs/providers/bedrock)[**📄️LiteLLM Proxy (LLM Gateway)** \\
\| Property \| Details \|](https://docs.litellm.ai/docs/providers/litellm_proxy)[**📄️Meta Llama** \\
\| Property \| Details \|](https://docs.litellm.ai/docs/providers/meta_llama)[**📄️Mistral AI API** \\
https://docs.mistral.ai/api/](https://docs.litellm.ai/docs/providers/mistral)[**📄️Codestral API \[Mistral AI\]** \\
Codestral is available in select code-completion plugins but can also be queried directly. See the documentation for more details.](https://docs.litellm.ai/docs/providers/codestral)[**📄️Cohere** \\
API KEYS](https://docs.litellm.ai/docs/providers/cohere)[**📄️Anyscale** \\
https://app.endpoints.anyscale.com/](https://docs.litellm.ai/docs/providers/anyscale)[**🗃️HuggingFace** \\
2 items](https://docs.litellm.ai/docs/providers/huggingface)[**📄️Databricks** \\
LiteLLM supports all models on Databricks](https://docs.litellm.ai/docs/providers/databricks)[**📄️Deepgram** \\
LiteLLM supports Deepgram's /listen endpoint.](https://docs.litellm.ai/docs/providers/deepgram)[**📄️IBM watsonx.ai** \\
LiteLLM supports all IBM watsonx.ai foundational models and embeddings.](https://docs.litellm.ai/docs/providers/watsonx)[**📄️Predibase** \\
LiteLLM supports all models on Predibase](https://docs.litellm.ai/docs/providers/predibase)[**📄️Nvidia NIM** \\
https://docs.api.nvidia.com/nim/reference/](https://docs.litellm.ai/docs/providers/nvidia_nim)[**📄️Nscale (EU Sovereign)** \\
https://docs.nscale.com/docs/inference/chat](https://docs.litellm.ai/docs/providers/nscale)[**📄️xAI** \\
https://docs.x.ai/docs](https://docs.litellm.ai/docs/providers/xai)[**📄️LM Studio** \\
https://lmstudio.ai/docs/basics/server](https://docs.litellm.ai/docs/providers/lm_studio)[**📄️Cerebras** \\
https://inference-docs.cerebras.ai/api-reference/chat-completions](https://docs.litellm.ai/docs/providers/cerebras)[**📄️Volcano Engine (Volcengine)** \\
https://www.volcengine.com/docs/82379/1263482](https://docs.litellm.ai/docs/providers/volcano)[**📄️Triton Inference Server** \\
LiteLLM supports Embedding Models on Triton Inference Servers](https://docs.litellm.ai/docs/providers/triton-inference-server)[**📄️Ollama** \\
LiteLLM supports all models from Ollama](https://docs.litellm.ai/docs/providers/ollama)[**📄️Perplexity AI (pplx-api)** \\
https://www.perplexity.ai](https://docs.litellm.ai/docs/providers/perplexity)[**📄️FriendliAI** \\
We support ALL FriendliAI models, just set friendliai/ as a prefix when sending completion requests](https://docs.litellm.ai/docs/providers/friendliai)[**📄️Galadriel** \\
https://docs.galadriel.com/api-reference/chat-completion-API](https://docs.litellm.ai/docs/providers/galadriel)[**📄️Topaz** \\
\| Property \| Details \|](https://docs.litellm.ai/docs/providers/topaz)[**📄️Groq** \\
https://groq.com/](https://docs.litellm.ai/docs/providers/groq)[**📄️🆕 Github** \\
https://github.com/marketplace/models](https://docs.litellm.ai/docs/providers/github)[**📄️Deepseek** \\
https://deepseek.com/](https://docs.litellm.ai/docs/providers/deepseek)[**📄️Fireworks AI** \\
We support ALL Fireworks AI models, just set fireworks\_ai/ as a prefix when sending completion requests](https://docs.litellm.ai/docs/providers/fireworks_ai)[**📄️Clarifai** \\
Anthropic, OpenAI, Mistral, Llama and Gemini LLMs are Supported on Clarifai.](https://docs.litellm.ai/docs/providers/clarifai)[**📄️VLLM** \\
LiteLLM supports all models on VLLM.](https://docs.litellm.ai/docs/providers/vllm)[**📄️Llamafile** \\
LiteLLM supports all models on Llamafile.](https://docs.litellm.ai/docs/providers/llamafile)[**📄️Infinity** \\
\| Property \| Details \|](https://docs.litellm.ai/docs/providers/infinity)[**📄️Xinference \[Xorbits Inference\]** \\
https://inference.readthedocs.io/en/latest/index.html](https://docs.litellm.ai/docs/providers/xinference)[**📄️Cloudflare Workers AI** \\
https://developers.cloudflare.com/workers-ai/models/text-generation/](https://docs.litellm.ai/docs/providers/cloudflare_workers)[**📄️DeepInfra** \\
https://deepinfra.com/](https://docs.litellm.ai/docs/providers/deepinfra)[**📄️AI21** \\
LiteLLM supports the following AI21 models:](https://docs.litellm.ai/docs/providers/ai21)[**📄️NLP Cloud** \\
LiteLLM supports all LLMs on NLP Cloud.](https://docs.litellm.ai/docs/providers/nlp_cloud)[**📄️Replicate** \\
LiteLLM supports all models on Replicate](https://docs.litellm.ai/docs/providers/replicate)[**📄️Together AI** \\
LiteLLM supports all models on Together AI.](https://docs.litellm.ai/docs/providers/togetherai)[**📄️Novita AI** \\
\| Property \| Details \|](https://docs.litellm.ai/docs/providers/novita)[**📄️Voyage AI** \\
https://docs.voyageai.com/embeddings/](https://docs.litellm.ai/docs/providers/voyage)[**📄️Jina AI** \\
https://jina.ai/embeddings/](https://docs.litellm.ai/docs/providers/jina_ai)[**📄️Aleph Alpha** \\
LiteLLM supports all models from Aleph Alpha.](https://docs.litellm.ai/docs/providers/aleph_alpha)[**📄️Baseten** \\
LiteLLM supports any Text-Gen-Interface models on Baseten.](https://docs.litellm.ai/docs/providers/baseten)[**📄️OpenRouter** \\
LiteLLM supports all the text / chat / vision models from OpenRouter](https://docs.litellm.ai/docs/providers/openrouter)[**📄️SambaNova** \\
https://cloud.sambanova.ai/](https://docs.litellm.ai/docs/providers/sambanova)[**📄️Custom API Server (Custom Format)** \\
Call your custom torch-serve / internal LLM APIs via LiteLLM](https://docs.litellm.ai/docs/providers/custom_llm_server)[**📄️Petals** \\
Petals//github.com/bigscience-workshop/petals](https://docs.litellm.ai/docs/providers/petals)[**📄️Snowflake** \\
\| Property \| Details \|](https://docs.litellm.ai/docs/providers/snowflake)[**📄️Featherless AI** \\
https://featherless.ai/](https://docs.litellm.ai/docs/providers/featherless_ai)[**📄️Nebius AI Studio** \\
https://docs.nebius.com/studio/inference/quickstart](https://docs.litellm.ai/docs/providers/nebius)