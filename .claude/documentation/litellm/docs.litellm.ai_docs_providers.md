---
url: "https://docs.litellm.ai/docs/providers"
title: "Providers | liteLLM"
---

[Skip to main content](https://docs.litellm.ai/docs/providers#__docusaurus_skipToContent_fallback)

[**ğŸ—ƒï¸OpenAI** \\
3 items](https://docs.litellm.ai/docs/providers/openai)[**ğŸ“„ï¸OpenAI (Text Completion)** \\
LiteLLM supports OpenAI text completion models](https://docs.litellm.ai/docs/providers/text_completion_openai)[**ğŸ“„ï¸OpenAI-Compatible Endpoints** \\
Selecting openai as the provider routes your request to an OpenAI-compatible endpoint using the upstream](https://docs.litellm.ai/docs/providers/openai_compatible)[**ğŸ—ƒï¸Azure OpenAI** \\
2 items](https://docs.litellm.ai/docs/providers/azure/)[**ğŸ“„ï¸Azure AI Studio** \\
LiteLLM supports all models on Azure AI Studio](https://docs.litellm.ai/docs/providers/azure_ai)[**ğŸ“„ï¸AI/ML API** \\
Getting started with the AI/ML API is simple. Follow these steps to set up your integration:](https://docs.litellm.ai/docs/providers/aiml)[**ğŸ“„ï¸VertexAI \[Anthropic, Gemini, Model Garden\]** \\
Overview](https://docs.litellm.ai/docs/providers/vertex)[**ğŸ—ƒï¸Google AI Studio** \\
3 items](https://docs.litellm.ai/docs/providers/gemini)[**ğŸ“„ï¸Anthropic** \\
LiteLLM supports all anthropic models.](https://docs.litellm.ai/docs/providers/anthropic)[**ğŸ“„ï¸AWS Sagemaker** \\
LiteLLM supports All Sagemaker Huggingface Jumpstart Models](https://docs.litellm.ai/docs/providers/aws_sagemaker)[**ğŸ—ƒï¸Bedrock** \\
3 items](https://docs.litellm.ai/docs/providers/bedrock)[**ğŸ“„ï¸LiteLLM Proxy (LLM Gateway)** \\
\| Property \| Details \|](https://docs.litellm.ai/docs/providers/litellm_proxy)[**ğŸ“„ï¸Meta Llama** \\
\| Property \| Details \|](https://docs.litellm.ai/docs/providers/meta_llama)[**ğŸ“„ï¸Mistral AI API** \\
https://docs.mistral.ai/api/](https://docs.litellm.ai/docs/providers/mistral)[**ğŸ“„ï¸Codestral API \[Mistral AI\]** \\
Codestral is available in select code-completion plugins but can also be queried directly. See the documentation for more details.](https://docs.litellm.ai/docs/providers/codestral)[**ğŸ“„ï¸Cohere** \\
API KEYS](https://docs.litellm.ai/docs/providers/cohere)[**ğŸ“„ï¸Anyscale** \\
https://app.endpoints.anyscale.com/](https://docs.litellm.ai/docs/providers/anyscale)[**ğŸ—ƒï¸HuggingFace** \\
2 items](https://docs.litellm.ai/docs/providers/huggingface)[**ğŸ“„ï¸Databricks** \\
LiteLLM supports all models on Databricks](https://docs.litellm.ai/docs/providers/databricks)[**ğŸ“„ï¸Deepgram** \\
LiteLLM supports Deepgram's /listen endpoint.](https://docs.litellm.ai/docs/providers/deepgram)[**ğŸ“„ï¸IBM watsonx.ai** \\
LiteLLM supports all IBM watsonx.ai foundational models and embeddings.](https://docs.litellm.ai/docs/providers/watsonx)[**ğŸ“„ï¸Predibase** \\
LiteLLM supports all models on Predibase](https://docs.litellm.ai/docs/providers/predibase)[**ğŸ“„ï¸Nvidia NIM** \\
https://docs.api.nvidia.com/nim/reference/](https://docs.litellm.ai/docs/providers/nvidia_nim)[**ğŸ“„ï¸Nscale (EU Sovereign)** \\
https://docs.nscale.com/docs/inference/chat](https://docs.litellm.ai/docs/providers/nscale)[**ğŸ“„ï¸xAI** \\
https://docs.x.ai/docs](https://docs.litellm.ai/docs/providers/xai)[**ğŸ“„ï¸LM Studio** \\
https://lmstudio.ai/docs/basics/server](https://docs.litellm.ai/docs/providers/lm_studio)[**ğŸ“„ï¸Cerebras** \\
https://inference-docs.cerebras.ai/api-reference/chat-completions](https://docs.litellm.ai/docs/providers/cerebras)[**ğŸ“„ï¸Volcano Engine (Volcengine)** \\
https://www.volcengine.com/docs/82379/1263482](https://docs.litellm.ai/docs/providers/volcano)[**ğŸ“„ï¸Triton Inference Server** \\
LiteLLM supports Embedding Models on Triton Inference Servers](https://docs.litellm.ai/docs/providers/triton-inference-server)[**ğŸ“„ï¸Ollama** \\
LiteLLM supports all models from Ollama](https://docs.litellm.ai/docs/providers/ollama)[**ğŸ“„ï¸Perplexity AI (pplx-api)** \\
https://www.perplexity.ai](https://docs.litellm.ai/docs/providers/perplexity)[**ğŸ“„ï¸FriendliAI** \\
We support ALL FriendliAI models, just set friendliai/ as a prefix when sending completion requests](https://docs.litellm.ai/docs/providers/friendliai)[**ğŸ“„ï¸Galadriel** \\
https://docs.galadriel.com/api-reference/chat-completion-API](https://docs.litellm.ai/docs/providers/galadriel)[**ğŸ“„ï¸Topaz** \\
\| Property \| Details \|](https://docs.litellm.ai/docs/providers/topaz)[**ğŸ“„ï¸Groq** \\
https://groq.com/](https://docs.litellm.ai/docs/providers/groq)[**ğŸ“„ï¸ğŸ†• Github** \\
https://github.com/marketplace/models](https://docs.litellm.ai/docs/providers/github)[**ğŸ“„ï¸Deepseek** \\
https://deepseek.com/](https://docs.litellm.ai/docs/providers/deepseek)[**ğŸ“„ï¸Fireworks AI** \\
We support ALL Fireworks AI models, just set fireworks\_ai/ as a prefix when sending completion requests](https://docs.litellm.ai/docs/providers/fireworks_ai)[**ğŸ“„ï¸Clarifai** \\
Anthropic, OpenAI, Mistral, Llama and Gemini LLMs are Supported on Clarifai.](https://docs.litellm.ai/docs/providers/clarifai)[**ğŸ“„ï¸VLLM** \\
LiteLLM supports all models on VLLM.](https://docs.litellm.ai/docs/providers/vllm)[**ğŸ“„ï¸Llamafile** \\
LiteLLM supports all models on Llamafile.](https://docs.litellm.ai/docs/providers/llamafile)[**ğŸ“„ï¸Infinity** \\
\| Property \| Details \|](https://docs.litellm.ai/docs/providers/infinity)[**ğŸ“„ï¸Xinference \[Xorbits Inference\]** \\
https://inference.readthedocs.io/en/latest/index.html](https://docs.litellm.ai/docs/providers/xinference)[**ğŸ“„ï¸Cloudflare Workers AI** \\
https://developers.cloudflare.com/workers-ai/models/text-generation/](https://docs.litellm.ai/docs/providers/cloudflare_workers)[**ğŸ“„ï¸DeepInfra** \\
https://deepinfra.com/](https://docs.litellm.ai/docs/providers/deepinfra)[**ğŸ“„ï¸AI21** \\
LiteLLM supports the following AI21 models:](https://docs.litellm.ai/docs/providers/ai21)[**ğŸ“„ï¸NLP Cloud** \\
LiteLLM supports all LLMs on NLP Cloud.](https://docs.litellm.ai/docs/providers/nlp_cloud)[**ğŸ“„ï¸Replicate** \\
LiteLLM supports all models on Replicate](https://docs.litellm.ai/docs/providers/replicate)[**ğŸ“„ï¸Together AI** \\
LiteLLM supports all models on Together AI.](https://docs.litellm.ai/docs/providers/togetherai)[**ğŸ“„ï¸Novita AI** \\
\| Property \| Details \|](https://docs.litellm.ai/docs/providers/novita)[**ğŸ“„ï¸Voyage AI** \\
https://docs.voyageai.com/embeddings/](https://docs.litellm.ai/docs/providers/voyage)[**ğŸ“„ï¸Jina AI** \\
https://jina.ai/embeddings/](https://docs.litellm.ai/docs/providers/jina_ai)[**ğŸ“„ï¸Aleph Alpha** \\
LiteLLM supports all models from Aleph Alpha.](https://docs.litellm.ai/docs/providers/aleph_alpha)[**ğŸ“„ï¸Baseten** \\
LiteLLM supports any Text-Gen-Interface models on Baseten.](https://docs.litellm.ai/docs/providers/baseten)[**ğŸ“„ï¸OpenRouter** \\
LiteLLM supports all the text / chat / vision models from OpenRouter](https://docs.litellm.ai/docs/providers/openrouter)[**ğŸ“„ï¸SambaNova** \\
https://cloud.sambanova.ai/](https://docs.litellm.ai/docs/providers/sambanova)[**ğŸ“„ï¸Custom API Server (Custom Format)** \\
Call your custom torch-serve / internal LLM APIs via LiteLLM](https://docs.litellm.ai/docs/providers/custom_llm_server)[**ğŸ“„ï¸Petals** \\
Petals//github.com/bigscience-workshop/petals](https://docs.litellm.ai/docs/providers/petals)[**ğŸ“„ï¸Snowflake** \\
\| Property \| Details \|](https://docs.litellm.ai/docs/providers/snowflake)[**ğŸ“„ï¸Featherless AI** \\
https://featherless.ai/](https://docs.litellm.ai/docs/providers/featherless_ai)[**ğŸ“„ï¸Nebius AI Studio** \\
https://docs.nebius.com/studio/inference/quickstart](https://docs.litellm.ai/docs/providers/nebius)