---
url: "https://docs.litellm.ai/docs/supported_endpoints"
title: "Supported Endpoints | liteLLM"
---

[Skip to main content](https://docs.litellm.ai/docs/supported_endpoints#__docusaurus_skipToContent_fallback)

[**🗃️/chat/completions** \\
3 items](https://docs.litellm.ai/docs/completion)[**📄️/responses \[Beta\]** \\
LiteLLM provides a BETA endpoint in the spec of OpenAI's /responses API](https://docs.litellm.ai/docs/response_api)[**📄️/completions** \\
Usage](https://docs.litellm.ai/docs/text_completion)[**📄️/embeddings** \\
Quick Start](https://docs.litellm.ai/docs/embedding/supported_embedding)[**📄️/v1/messages \[BETA\]** \\
Use LiteLLM to call all your LLM APIs in the Anthropic v1/messages format.](https://docs.litellm.ai/docs/anthropic_unified)[**📄️/mcp \[BETA\] - Model Context Protocol** \\
Expose MCP tools on LiteLLM Proxy Server](https://docs.litellm.ai/docs/mcp)[**🗃️/images** \\
3 items](https://docs.litellm.ai/docs/image_generation)[**🗃️/audio** \\
2 items](https://docs.litellm.ai/docs/audio_transcription)[**🗃️Pass-through Endpoints (Anthropic SDK, etc.)** \\
12 items](https://docs.litellm.ai/docs/pass_through/intro)[**📄️/rerank** \\
LiteLLM Follows the cohere api request / response for the rerank api](https://docs.litellm.ai/docs/rerank)[**📄️/assistants** \\
Covers Threads, Messages, Assistants.](https://docs.litellm.ai/docs/assistants)[**🗃️/files** \\
2 items](https://docs.litellm.ai/docs/files_endpoints)[**🗃️/batches** \\
2 items](https://docs.litellm.ai/docs/batches)[**📄️/realtime** \\
Use this to loadbalance across Azure + OpenAI.](https://docs.litellm.ai/docs/realtime)[**🗃️/fine\_tuning** \\
2 items](https://docs.litellm.ai/docs/fine_tuning)[**📄️/moderations** \\
Usage](https://docs.litellm.ai/docs/moderation)[**📄️/guardrails/apply\_guardrail** \\
Use this endpoint to directly call a guardrail configured on your LiteLLM instance. This is useful when you have services that need to directly call a guardrail.](https://docs.litellm.ai/docs/apply_guardrail)