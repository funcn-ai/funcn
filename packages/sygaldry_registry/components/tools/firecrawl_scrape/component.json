{
  "$schema": "https://sygaldry.ai/schemas/component.json",
  "name": "firecrawl-scrape-tool",
  "version": "0.1.0",
  "description": "Firecrawl-powered web scraping tool that extracts clean, structured content from websites. Handles JavaScript-rendered pages and provides multiple output formats including Markdown, HTML, and screenshots.",
  "type": "tool",
  "authors": [
    {
      "name": "Sygaldry Project",
      "email": "info@sygaldry.ai"
    }
  ],
  "license": "MIT",
  "repository_url": "https://github.com/greyhaven-ai/sygaldry",
  "mirascope_version_min": "1.24.0",
  "files_to_copy": [
    {
      "source": "tool.py",
      "destination": "tool.py",
      "type": "module"
    },
    {
      "source": "__init__.py",
      "destination": "__init__.py",
      "type": "init_file"
    }
  ],
  "target_directory_key": "tools",
  "python_dependencies": [
    "firecrawl-py>=0.0.16",
    "pydantic>=2.0.0"
  ],
  "registry_dependencies": [],
  "environment_variables": [],
  "example_usage": "```python\nimport asyncio\nfrom firecrawl_scrape import scrape_website, FirecrawlScrapeArgs\n\nasync def main():\n    # Basic scrape for main content\n    scrape_args = FirecrawlScrapeArgs(\n        url=\"https://example.com/article\",\n        formats=[\"markdown\", \"links\"],\n        only_main_content=True\n    )\n    \n    response = await scrape_website(scrape_args)\n    \n    if response.success:\n        print(f\"Title: {response.metadata.title if response.metadata else 'N/A'}\")\n        print(f\"\\nContent (Markdown):\\n{response.markdown[:500]}...\")\n        print(f\"\\nFound {len(response.links)} links\")\n    else:\n        print(f\"Error: {response.error}\")\n    \n    # Advanced scrape with specific selectors\n    advanced_args = FirecrawlScrapeArgs(\n        url=\"https://news.ycombinator.com\",\n        formats=[\"html\", \"content\", \"screenshot\"],\n        include_tags=[\".athing\", \".title\"],\n        exclude_tags=[\".spacer\", \".morelink\"],\n        wait_for=2000,  # Wait 2 seconds for dynamic content\n        screenshot=True\n    )\n    \n    advanced_response = await scrape_website(advanced_args)\n    \n    if advanced_response.success:\n        print(f\"\\nExtracted {len(advanced_response.content.split())} words\")\n        if advanced_response.screenshot:\n            print(\"Screenshot captured successfully\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```",
  "post_add_instructions": "The Firecrawl scraping tool is now available for extracting structured content from websites. Make sure to set your FIRECRAWL_API_KEY environment variable.\n\nKey features:\n1. **Multiple output formats**: Markdown, HTML, plain text, links, and screenshots\n2. **JavaScript support**: Handles dynamic content with configurable wait times\n3. **Content filtering**: Include/exclude specific elements using CSS selectors\n4. **Main content extraction**: Automatically removes navigation, ads, and other non-content elements\n5. **Rich metadata**: Extracts Open Graph, Twitter Card, and standard meta tags\n\nThis tool is ideal for:\n- Content extraction for analysis\n- Building datasets from web content\n- Monitoring website changes\n- Creating readable versions of web pages\n- Extracting structured data from JavaScript-heavy sites",
  "tags": [
    "web-scraping",
    "firecrawl",
    "content-extraction",
    "javascript",
    "markdown",
    "html",
    "screenshot"
  ],
  "supports_lilypad": true,
  "template_variables": {},
  "mcp_compatible": false,
  "mcp_entrypoint": ""
}
